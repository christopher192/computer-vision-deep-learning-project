{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5b5dd9",
   "metadata": {},
   "source": [
    "## Faster RCNN Fine-tuning with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8fb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.ops import MultiScaleRoIAlign\n",
    "from torchvision.models.detection import FasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b8d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" \n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949981f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = True)\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights = 'FasterRCNN_ResNet50_FPN_Weights.DEFAULT')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0e39aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image size: torch.Size([3, 359, 360])\n",
      "Second image size: torch.Size([3, 376, 508])\n"
     ]
    }
   ],
   "source": [
    "first_image = T.ToTensor()(Image.open('image/FudanPed00066.png'))\n",
    "first_box = torch.tensor([[248.0, 50.0, 329.0, 351.0]])\n",
    "first_label = torch.tensor([1])\n",
    "\n",
    "second_image = T.ToTensor()(Image.open('image/PennPed00011.png'))\n",
    "second_box = torch.tensor([[92.0, 62.0, 236.0, 344.0], [242.0, 52.0, 301.0, 355.0]])\n",
    "second_label = torch.tensor([1, 1])\n",
    "\n",
    "print('First image size: {}'.format(first_image.size()))\n",
    "print('Second image size: {}'.format(second_image.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e5b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[243.2258,  47.7818, 327.8421, 349.9229],\n",
      "        [305.6328,  99.5300, 330.0190, 128.9751]], grad_fn=<StackBackward0>), 'labels': tensor([ 1, 34]), 'scores': tensor([0.9997, 0.0594], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[ 89.9230,  59.4910, 225.3071, 342.8299],\n",
      "        [244.2283,  49.8334, 304.4795, 362.8903],\n",
      "        [245.9230, 127.6201, 276.5671, 197.8546],\n",
      "        [252.0380,  15.8489, 369.9043, 367.3777],\n",
      "        [245.7938,  99.7875, 294.3491, 198.7888],\n",
      "        [243.9077, 121.8000, 276.3352, 198.4012],\n",
      "        [247.6824,  51.5020, 301.1053, 203.1744],\n",
      "        [245.5552,  95.3306, 295.3181, 199.0098],\n",
      "        [274.8139,  96.3891, 301.2039, 188.7243],\n",
      "        [123.6462,  56.9277, 191.9256, 338.0053],\n",
      "        [240.7440,  44.0858, 333.5300, 235.6630],\n",
      "        [267.6390, 100.0402, 299.7915, 187.5079]], grad_fn=<StackBackward0>), 'labels': tensor([ 1,  1, 27,  1, 27, 31,  1, 31, 27,  1,  1, 31]), 'scores': tensor([0.9996, 0.9931, 0.7120, 0.6038, 0.3407, 0.3300, 0.3079, 0.2703, 0.2572,\n",
      "        0.0977, 0.0517, 0.0514], grad_fn=<IndexBackward0>)}]\n"
     ]
    }
   ],
   "source": [
    "first_input_image = first_image.clone()\n",
    "second_input_image = second_image.clone()\n",
    "\n",
    "inputs = [first_input_image.to(device), second_input_image.to(device)]\n",
    "\n",
    "model.eval()\n",
    "output = model(inputs)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a58719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(0.0286, grad_fn=<NllLossBackward0>),\n",
       " 'loss_box_reg': tensor(0.0299, grad_fn=<DivBackward0>),\n",
       " 'loss_objectness': tensor(0.0118, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " 'loss_rpn_box_reg': tensor(0.0048, grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_input_image = first_image.clone()\n",
    "first_target = {\n",
    "    'boxes': first_box.clone().to(device),\n",
    "    'labels' : first_label.clone().to(device)\n",
    "    \n",
    "} \n",
    "\n",
    "second_input_image = second_image.clone()\n",
    "second_target = {\n",
    "    'boxes': second_box.clone().to(device),\n",
    "    'labels' : second_label.clone().to(device)\n",
    "    \n",
    "} \n",
    "\n",
    "inputs = [first_input_image.to(device), second_input_image.to(device)]\n",
    "targets = [first_target, second_target]\n",
    "\n",
    "model.train()\n",
    "model(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68bbd630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0-3): 4 x Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5205f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor size: torch.Size([2, 3, 800, 1088])\n"
     ]
    }
   ],
   "source": [
    "first_image = first_image.clone()\n",
    "second_image = second_image.clone()\n",
    "\n",
    "inputs = [first_image.to(device), second_image.to(device)]\n",
    "trans_image_list, trans_target_list = model.transform(inputs)\n",
    "\n",
    "print('Tensor size: {}'.format(trans_image_list.tensors.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b53df52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform ( GeneralizedRCNNTransform) parameters:\n",
      "min_size: (800,)\n",
      "max_size: 1333\n",
      "image_mean: [0.485, 0.456, 0.406]\n",
      "image_std: [0.229, 0.224, 0.225]\n"
     ]
    }
   ],
   "source": [
    "print('transform ( GeneralizedRCNNTransform) parameters:')\n",
    "print('min_size: {}'.format(model.transform.min_size))\n",
    "print('max_size: {}'.format(model.transform.max_size))\n",
    "print('image_mean: {}'.format(model.transform.image_mean))\n",
    "print('image_std: {}'.format(model.transform.image_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75c6f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_min_size = 300\n",
    "ft_max_size = 500\n",
    "\n",
    "ft_mean = [0.485, 0.456, 0.406]\n",
    "ft_std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc960863",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_out = model.backbone(trans_image_list.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd212a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: torch.Size([2, 256, 200, 272])\n",
      "1: torch.Size([2, 256, 100, 136])\n",
      "2: torch.Size([2, 256, 50, 68])\n",
      "3: torch.Size([2, 256, 25, 34])\n",
      "pool: torch.Size([2, 256, 13, 17])\n"
     ]
    }
   ],
   "source": [
    "for key, value in backbone_out.items():\n",
    "    print('{}: {}'.format(key, value.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defd3b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of output channel of the backbone: 256\n"
     ]
    }
   ],
   "source": [
    "print('Number of output channel of the backbone: {}'.format(model.backbone.out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99d9913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "alexnet = models.alexnet(weights = 'AlexNet_Weights.DEFAULT')\n",
    "\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54c937df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_backbone = alexnet.features\n",
    "ft_backbone.out_channels = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf8fb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionProposalNetwork(\n",
       "  (anchor_generator): AnchorGenerator()\n",
       "  (head): RPNHead(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67e717d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor sizes: ((32,), (64,), (128,), (256,), (512,))\n",
      "Aspect ratios: ((0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0), (0.5, 1.0, 2.0))\n"
     ]
    }
   ],
   "source": [
    "print('Anchor sizes: {}'.format(model.rpn.anchor_generator.sizes))\n",
    "print('Aspect ratios: {}'.format(model.rpn.anchor_generator.aspect_ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415e6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_anchor_generator = AnchorGenerator(sizes = ((32, 64, 128, 256),), \n",
    "                                      aspect_ratios = ((0.5, 1.0, 2.0),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb3724a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoIHeads(\n",
       "  (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "  (box_head): TwoMLPHead(\n",
       "    (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "    (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (box_predictor): FastRCNNPredictor(\n",
       "    (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "    (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roi_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "972ec1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box RoI Pool Parameters:\n",
      "featmap_names: ['0', '1', '2', '3']\n",
      "output_size: (7, 7)\n",
      "sampling_ratio: 2\n"
     ]
    }
   ],
   "source": [
    "print('Box RoI Pool Parameters:')\n",
    "print('featmap_names: {}'.format(model.roi_heads.box_roi_pool.featmap_names))\n",
    "print('output_size: {}'.format(model.roi_heads.box_roi_pool.output_size))\n",
    "print('sampling_ratio: {}'.format(model.roi_heads.box_roi_pool.sampling_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e043fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0', '1', '2', '3', 'pool'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "303590b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ft_backbone(torch.rand((2, 3, 300, 300))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "489d3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_roi_pooler = MultiScaleRoIAlign(featmap_names = ['0'], output_size = 4, sampling_ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f537d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FasterRCNN(backbone = ft_backbone,\n",
    "                      num_classes = 2, \n",
    "                      min_size = ft_min_size, \n",
    "                      max_size = ft_max_size, \n",
    "                      image_mean = ft_mean, \n",
    "                      image_std = ft_std, \n",
    "                      rpn_anchor_generator = ft_anchor_generator, \n",
    "                      box_roi_pool = ft_roi_pooler)\n",
    "\n",
    "ft_model = ft_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfce8390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[2.6733e+02, 2.2384e+02, 3.5762e+02, 2.8285e+02],\n",
      "        [2.6513e+02, 1.6276e+02, 3.5750e+02, 2.6657e+02],\n",
      "        [1.9986e+02, 1.3859e+02, 3.4652e+02, 2.7779e+02],\n",
      "        [2.7702e+02, 1.8531e+02, 3.5778e+02, 2.4385e+02],\n",
      "        [2.7293e+02, 2.2097e+02, 2.9775e+02, 2.7886e+02],\n",
      "        [3.1392e+02, 2.1970e+02, 3.3927e+02, 2.7543e+02],\n",
      "        [4.4749e+01, 2.7552e+02, 2.7225e+02, 3.5855e+02],\n",
      "        [2.5415e+02, 1.9821e+02, 3.2132e+02, 2.7473e+02],\n",
      "        [1.3625e+02, 5.5600e+01, 2.7576e+02, 2.1266e+02],\n",
      "        [2.3665e+02, 2.1160e+02, 3.5652e+02, 3.0696e+02],\n",
      "        [2.1023e+02, 1.6492e+02, 2.7849e+02, 2.3933e+02],\n",
      "        [2.3371e+02, 1.2491e+02, 3.5783e+02, 2.3790e+02],\n",
      "        [3.0065e+02, 1.9469e+02, 3.5872e+02, 2.2561e+02],\n",
      "        [3.0588e+02, 0.0000e+00, 3.5984e+02, 3.0096e+02],\n",
      "        [1.6422e+02, 1.5799e+02, 2.3592e+02, 1.8227e+02],\n",
      "        [2.9139e+02, 9.3688e-01, 3.5899e+02, 1.5399e+02],\n",
      "        [1.1008e+02, 3.1326e+02, 2.1641e+02, 3.5856e+02],\n",
      "        [1.1120e+02, 1.1010e+02, 2.8762e+02, 3.5434e+02],\n",
      "        [2.3365e+02, 1.9071e+02, 3.3351e+02, 2.4228e+02],\n",
      "        [0.0000e+00, 4.8297e+01, 7.9951e+01, 2.8490e+02],\n",
      "        [2.5218e+02, 1.5368e+02, 3.2540e+02, 2.3400e+02],\n",
      "        [1.9145e+02, 1.9070e+02, 2.1596e+02, 2.4769e+02],\n",
      "        [2.6779e+02, 1.3171e+02, 3.5841e+02, 3.5703e+02],\n",
      "        [0.0000e+00, 1.1386e+02, 1.2339e+02, 2.2464e+02],\n",
      "        [3.0598e+02, 2.0577e+02, 3.5932e+02, 3.0828e+02],\n",
      "        [1.6171e+02, 1.8704e+02, 2.4254e+02, 2.3895e+02],\n",
      "        [9.4830e-02, 1.4686e+02, 8.5785e+01, 2.0133e+02],\n",
      "        [0.0000e+00, 5.5983e+01, 2.8733e+02, 2.7277e+02],\n",
      "        [1.6068e+02, 1.4570e+02, 2.4445e+02, 1.9718e+02],\n",
      "        [8.1718e+01, 1.8537e+02, 2.5288e+02, 3.2949e+02],\n",
      "        [3.4898e+02, 2.2702e+02, 3.5985e+02, 2.7961e+02],\n",
      "        [8.3444e+00, 1.5628e+02, 6.9215e+01, 1.8298e+02],\n",
      "        [1.1847e+02, 2.2296e+02, 2.7011e+02, 3.5871e+02],\n",
      "        [2.6037e+01, 1.4581e+02, 5.3676e+01, 2.0097e+02],\n",
      "        [2.3264e+02, 1.9033e+02, 2.5665e+02, 2.4150e+02],\n",
      "        [1.5801e+02, 0.0000e+00, 2.3775e+02, 2.2975e+02],\n",
      "        [3.1472e+02, 1.8471e+02, 3.3817e+02, 2.3944e+02],\n",
      "        [3.3802e+02, 3.2133e+02, 3.5969e+02, 3.5011e+02],\n",
      "        [3.3068e+02, 2.0757e+02, 3.5956e+02, 2.8492e+02],\n",
      "        [3.0623e+02, 6.3545e+01, 3.5963e+02, 1.1772e+02],\n",
      "        [6.1582e+01, 3.0946e+02, 1.7710e+02, 3.5891e+02],\n",
      "        [2.6943e+02, 8.7161e-01, 3.5782e+02, 5.8207e+01],\n",
      "        [1.0868e+02, 2.7532e+02, 2.1543e+02, 3.2219e+02],\n",
      "        [3.1143e+01, 3.3381e+01, 1.2457e+02, 2.6973e+02],\n",
      "        [3.3987e+02, 3.2321e+01, 3.5987e+02, 1.4005e+02],\n",
      "        [2.5406e+02, 3.2846e+00, 3.5789e+02, 2.3100e+02],\n",
      "        [3.5201e+02, 5.9252e+01, 3.5995e+02, 1.1580e+02],\n",
      "        [2.7359e+02, 1.8615e+02, 2.9811e+02, 2.3810e+02],\n",
      "        [3.0982e+02, 5.6445e+01, 3.3624e+02, 1.1534e+02],\n",
      "        [2.8985e+02, 3.6909e+01, 3.5883e+02, 1.0908e+02],\n",
      "        [3.5131e+02, 1.0328e+02, 3.5994e+02, 1.5944e+02],\n",
      "        [2.5044e+01, 1.4513e+02, 1.2406e+02, 1.9902e+02],\n",
      "        [0.0000e+00, 8.8694e+01, 4.1675e+01, 3.0686e+02],\n",
      "        [0.0000e+00, 2.7775e+02, 1.3581e+01, 3.3645e+02],\n",
      "        [2.6073e+02, 4.7859e-01, 3.5791e+02, 3.0173e+01],\n",
      "        [0.0000e+00, 2.8006e+02, 2.9280e+01, 3.0972e+02],\n",
      "        [3.2792e+02, 4.1429e+01, 3.5982e+02, 1.1410e+02],\n",
      "        [3.4488e+02, 0.0000e+00, 3.5988e+02, 1.9446e+02],\n",
      "        [2.8370e+02, 7.5951e+01, 3.5735e+02, 1.4614e+02],\n",
      "        [1.2090e+02, 1.8515e+02, 2.1658e+02, 2.3788e+02],\n",
      "        [4.4492e+01, 2.3709e+02, 1.1854e+02, 3.2635e+02],\n",
      "        [1.2097e+02, 1.4271e+02, 2.1486e+02, 1.9454e+02],\n",
      "        [2.6426e+02, 2.5013e+01, 3.5619e+02, 8.5386e+01],\n",
      "        [2.9903e+02, 3.2163e+02, 3.5679e+02, 3.4821e+02],\n",
      "        [3.8389e-01, 6.7308e+01, 2.5702e+01, 1.7464e+02],\n",
      "        [2.3272e+02, 2.2532e+02, 2.5745e+02, 2.8260e+02],\n",
      "        [1.6921e+02, 2.3752e+02, 2.4239e+02, 3.1381e+02],\n",
      "        [5.0655e+01, 7.6844e+01, 3.0171e+02, 1.7992e+02],\n",
      "        [1.4652e+02, 3.1022e+02, 1.7658e+02, 3.5885e+02],\n",
      "        [4.9327e-01, 1.6742e+01, 4.7844e+01, 2.2975e+02],\n",
      "        [1.8945e+02, 5.9641e+01, 2.6832e+02, 3.2091e+02],\n",
      "        [3.5339e+02, 1.3715e+01, 3.5996e+02, 7.5671e+01],\n",
      "        [2.5673e+01, 0.0000e+00, 2.4142e+02, 5.6757e+01],\n",
      "        [1.4499e-01, 1.0954e+02, 2.9624e+01, 2.1818e+02],\n",
      "        [1.4223e+02, 0.0000e+00, 2.4268e+02, 2.8685e+01],\n",
      "        [2.9966e+02, 5.7245e+01, 3.4477e+02, 1.0183e+02],\n",
      "        [1.2330e+02, 8.1920e+01, 3.5522e+02, 2.9764e+02],\n",
      "        [1.4615e+02, 1.5512e+02, 2.3880e+02, 3.5756e+02],\n",
      "        [2.2938e+02, 2.6863e+02, 2.5502e+02, 3.2654e+02],\n",
      "        [2.8901e+02, 2.4684e+02, 3.5872e+02, 3.1950e+02],\n",
      "        [0.0000e+00, 3.1095e+02, 4.8403e+01, 3.5900e+02],\n",
      "        [2.6468e+02, 1.5062e+00, 3.2393e+02, 7.6360e+01],\n",
      "        [3.2972e+02, 7.8774e+01, 3.5979e+02, 1.5489e+02],\n",
      "        [6.4859e+00, 7.1729e+01, 6.9361e+01, 1.7964e+02],\n",
      "        [2.7122e+02, 5.5633e-01, 2.9536e+02, 2.8872e+01],\n",
      "        [1.9983e-01, 1.5666e+02, 3.0753e+01, 1.8260e+02],\n",
      "        [3.2574e+02, 1.7728e+02, 3.5970e+02, 3.2716e+02],\n",
      "        [5.9870e+01, 2.7053e+02, 1.7564e+02, 3.1966e+02],\n",
      "        [1.4023e-01, 1.0342e+02, 1.2683e+01, 1.6013e+02],\n",
      "        [1.3137e+02, 2.8182e+02, 1.9054e+02, 3.5890e+02],\n",
      "        [3.5204e+02, 2.6450e+02, 3.5992e+02, 3.1966e+02],\n",
      "        [1.7194e+02, 8.5518e+01, 2.4367e+02, 1.6859e+02],\n",
      "        [4.9530e-01, 1.0091e+02, 4.7416e+01, 1.5525e+02],\n",
      "        [8.5565e-02, 1.4303e+02, 1.3800e+01, 1.9883e+02],\n",
      "        [1.0666e+02, 3.1016e+02, 1.3735e+02, 3.5893e+02],\n",
      "        [0.0000e+00, 2.3188e+02, 4.8357e+01, 3.5900e+02],\n",
      "        [2.1845e-01, 7.2570e+01, 2.9285e+01, 9.7744e+01],\n",
      "        [4.7454e+01, 1.5562e+02, 1.1069e+02, 1.8123e+02],\n",
      "        [0.0000e+00, 3.1050e+02, 1.4225e+01, 3.5900e+02],\n",
      "        [3.5488e+02, 1.8370e+02, 3.5994e+02, 2.4032e+02]],\n",
      "       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.5697, 0.5623, 0.5542, 0.5487, 0.5425, 0.5388, 0.5373, 0.5369, 0.5348,\n",
      "        0.5342, 0.5329, 0.5325, 0.5310, 0.5305, 0.5297, 0.5293, 0.5287, 0.5276,\n",
      "        0.5274, 0.5273, 0.5271, 0.5266, 0.5261, 0.5256, 0.5242, 0.5238, 0.5232,\n",
      "        0.5229, 0.5214, 0.5199, 0.5198, 0.5196, 0.5194, 0.5194, 0.5187, 0.5187,\n",
      "        0.5179, 0.5172, 0.5162, 0.5160, 0.5157, 0.5152, 0.5150, 0.5141, 0.5140,\n",
      "        0.5140, 0.5138, 0.5137, 0.5135, 0.5135, 0.5135, 0.5133, 0.5130, 0.5124,\n",
      "        0.5124, 0.5122, 0.5119, 0.5111, 0.5107, 0.5106, 0.5106, 0.5104, 0.5104,\n",
      "        0.5096, 0.5094, 0.5090, 0.5090, 0.5089, 0.5089, 0.5087, 0.5084, 0.5080,\n",
      "        0.5068, 0.5068, 0.5067, 0.5064, 0.5064, 0.5062, 0.5059, 0.5056, 0.5055,\n",
      "        0.5054, 0.5052, 0.5051, 0.5050, 0.5049, 0.5046, 0.5044, 0.5043, 0.5043,\n",
      "        0.5042, 0.5042, 0.5038, 0.5037, 0.5035, 0.5030, 0.5029, 0.5028, 0.5028,\n",
      "        0.5027], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[1.9054e+02, 0.0000e+00, 4.1980e+02, 3.7600e+02],\n",
      "        [1.5988e+02, 3.0402e+02, 3.8044e+02, 3.7600e+02],\n",
      "        [2.2436e+02, 1.2372e+02, 3.2695e+02, 3.7442e+02],\n",
      "        [2.3790e+02, 1.2880e+02, 4.1027e+02, 2.9062e+02],\n",
      "        [3.7267e+02, 1.0205e-01, 4.7761e+02, 3.0991e+01],\n",
      "        [1.5596e+02, 8.0747e+01, 2.4528e+02, 3.1841e+02],\n",
      "        [2.5936e+02, 2.0550e+02, 3.3042e+02, 3.3077e+02],\n",
      "        [3.4233e+02, 5.8680e-01, 5.0316e+02, 8.8119e+01],\n",
      "        [1.5740e+00, 1.7372e+02, 9.4401e+01, 3.2999e+02],\n",
      "        [2.8281e+02, 2.3721e+02, 3.1039e+02, 3.0075e+02],\n",
      "        [2.3798e+02, 1.1719e+02, 4.7118e+02, 2.3508e+02],\n",
      "        [2.6197e+02, 3.2841e+02, 3.5763e+02, 3.7600e+02],\n",
      "        [2.7896e+02, 9.5119e+01, 3.7533e+02, 3.2707e+02],\n",
      "        [2.7346e+02, 1.5864e+02, 3.7182e+02, 2.1506e+02],\n",
      "        [0.0000e+00, 1.4108e+02, 4.3198e+01, 3.5261e+02],\n",
      "        [4.0324e+02, 8.2489e-02, 4.4698e+02, 1.9954e+01],\n",
      "        [2.3060e+02, 5.7756e+01, 5.0800e+02, 2.8739e+02],\n",
      "        [3.7127e+02, 1.9366e+01, 4.7659e+02, 7.7222e+01],\n",
      "        [4.3857e+02, 2.9507e+02, 4.9807e+02, 3.7529e+02],\n",
      "        [2.8534e+02, 1.5465e+02, 3.1167e+02, 2.1261e+02],\n",
      "        [4.2785e+02, 0.0000e+00, 5.0720e+02, 3.7384e+01],\n",
      "        [4.1366e+02, 3.2481e+02, 5.0721e+02, 3.7578e+02],\n",
      "        [3.9864e+02, 7.9909e-02, 4.5557e+02, 5.6074e+01],\n",
      "        [4.1514e+02, 2.8425e+02, 5.0774e+02, 3.3931e+02],\n",
      "        [3.1594e+02, 1.5505e+02, 3.6143e+02, 1.9859e+02],\n",
      "        [3.1553e+02, 3.2719e+02, 3.5807e+02, 3.7231e+02],\n",
      "        [4.5430e+02, 0.0000e+00, 4.8114e+02, 3.1869e+01],\n",
      "        [4.4702e+02, 0.0000e+00, 4.8929e+02, 1.9931e+01],\n",
      "        [3.5581e+02, 3.3735e+02, 4.1783e+02, 3.6647e+02],\n",
      "        [2.1580e+02, 3.2830e+02, 3.1366e+02, 3.7600e+02],\n",
      "        [1.2764e+02, 8.3910e+01, 3.4541e+02, 3.7600e+02],\n",
      "        [2.9281e+02, 1.9685e+00, 5.0750e+02, 1.7587e+02],\n",
      "        [2.3359e+02, 6.7512e+01, 4.5940e+02, 1.8866e+02],\n",
      "        [2.1843e+02, 2.9735e+02, 2.8082e+02, 3.7600e+02],\n",
      "        [1.3673e+01, 3.3611e+02, 7.5655e+01, 3.6667e+02],\n",
      "        [4.4603e+02, 2.8334e+02, 4.9112e+02, 3.2945e+02],\n",
      "        [3.0492e+02, 3.3223e+02, 4.0530e+02, 3.7600e+02],\n",
      "        [4.5441e+02, 3.2254e+02, 4.8311e+02, 3.7564e+02],\n",
      "        [3.9982e+02, 1.9005e+01, 4.4733e+02, 6.4133e+01],\n",
      "        [0.0000e+00, 3.3830e+02, 2.8039e+01, 3.6749e+02],\n",
      "        [4.1115e+02, 1.1575e-01, 4.3859e+02, 3.0347e+01],\n",
      "        [2.4927e+02, 3.0411e+02, 3.3814e+02, 3.7600e+02],\n",
      "        [7.3916e-01, 6.5827e+01, 1.0841e+02, 3.7600e+02],\n",
      "        [3.8981e+01, 2.5547e+00, 2.4477e+02, 3.3233e+02],\n",
      "        [1.7616e+02, 2.5160e+02, 2.5289e+02, 2.7698e+02],\n",
      "        [3.6564e+02, 1.5080e+02, 4.6174e+02, 2.0878e+02],\n",
      "        [2.8238e+02, 3.1798e+02, 3.0993e+02, 3.7600e+02],\n",
      "        [3.0582e+02, 1.5644e+02, 3.6693e+02, 2.6829e+02],\n",
      "        [0.0000e+00, 7.8446e+01, 3.9855e+02, 2.9525e+02],\n",
      "        [3.0495e+02, 1.3189e+02, 3.8019e+02, 2.1420e+02],\n",
      "        [1.8611e+02, 6.5615e+01, 2.8815e+02, 3.1658e+02],\n",
      "        [3.0016e+02, 3.0196e+02, 3.7860e+02, 3.7600e+02],\n",
      "        [3.7105e+02, 2.1072e-01, 3.9890e+02, 3.2814e+01],\n",
      "        [5.6267e+01, 1.5584e+00, 5.0181e+02, 1.9400e+02],\n",
      "        [3.2151e+02, 2.9494e+02, 5.0688e+02, 3.7600e+02],\n",
      "        [3.6901e+02, 3.2775e+02, 3.9759e+02, 3.7600e+02],\n",
      "        [2.0193e+02, 2.4312e+02, 2.2805e+02, 3.0862e+02],\n",
      "        [2.2687e+02, 3.2944e+02, 2.6806e+02, 3.7600e+02],\n",
      "        [3.4978e+02, 1.3346e+02, 4.3003e+02, 2.1737e+02],\n",
      "        [3.3403e+02, 1.0183e+02, 4.9663e+02, 2.6541e+02],\n",
      "        [3.7109e+02, 1.1492e+02, 5.0800e+02, 3.7600e+02],\n",
      "        [3.7143e+02, 1.4725e+02, 3.9783e+02, 2.0684e+02],\n",
      "        [4.0211e+02, 2.3959e+02, 5.0800e+02, 2.9537e+02],\n",
      "        [3.4866e+02, 3.4086e-01, 4.2909e+02, 3.2713e+01],\n",
      "        [2.8435e+02, 1.9698e+02, 3.1145e+02, 2.6046e+02],\n",
      "        [4.4022e+02, 3.3699e+02, 5.0123e+02, 3.6582e+02],\n",
      "        [3.2962e+02, 9.5432e+01, 4.1949e+02, 3.0939e+02],\n",
      "        [1.7911e+02, 2.3738e+02, 3.0108e+02, 2.9346e+02],\n",
      "        [2.0945e+02, 2.0713e+02, 2.9419e+02, 3.2425e+02],\n",
      "        [2.4040e+02, 2.6394e+02, 4.2124e+02, 3.7600e+02],\n",
      "        [4.3511e+02, 2.4373e+02, 4.9446e+02, 3.5659e+02],\n",
      "        [3.4758e+02, 3.0557e+02, 4.2402e+02, 3.7600e+02],\n",
      "        [4.3978e+02, 2.5148e+02, 4.9902e+02, 2.7843e+02],\n",
      "        [3.7520e+02, 1.1454e+00, 4.7502e+02, 1.4971e+02],\n",
      "        [2.7206e+02, 2.8265e+02, 3.1968e+02, 3.2857e+02],\n",
      "        [2.4268e+02, 2.3906e+02, 2.6716e+02, 3.0436e+02],\n",
      "        [2.6946e+02, 1.6104e+02, 5.0800e+02, 2.7404e+02],\n",
      "        [3.8156e+02, 9.2773e+01, 4.6806e+02, 3.0621e+02],\n",
      "        [3.5769e+02, 1.6253e+02, 4.1768e+02, 1.9082e+02],\n",
      "        [2.0072e+02, 1.9706e+02, 3.6704e+02, 3.6575e+02],\n",
      "        [0.0000e+00, 3.3103e+02, 1.1149e+02, 3.7597e+02],\n",
      "        [2.0194e+02, 2.8598e+02, 3.2294e+02, 3.3398e+02],\n",
      "        [4.0153e+02, 6.4687e+01, 4.4631e+02, 1.0677e+02],\n",
      "        [3.6838e+02, 2.5314e+02, 5.0800e+02, 3.6005e+02],\n",
      "        [3.1835e+02, 2.3722e+02, 3.6279e+02, 2.8458e+02],\n",
      "        [9.6360e+01, 1.7378e+02, 2.9000e+02, 3.1170e+02],\n",
      "        [3.8076e+01, 3.2941e+02, 1.5407e+02, 3.7600e+02],\n",
      "        [3.1918e+02, 1.0073e+00, 4.2618e+02, 2.0383e+02],\n",
      "        [6.0334e+01, 3.2733e+02, 1.0395e+02, 3.7369e+02],\n",
      "        [2.8399e+02, 2.8144e+02, 3.1020e+02, 3.4343e+02],\n",
      "        [3.8917e+02, 4.3706e+01, 4.6573e+02, 1.3343e+02],\n",
      "        [4.0897e+02, 1.6411e+01, 4.3641e+02, 7.7717e+01],\n",
      "        [1.9707e+02, 3.3095e+02, 2.2573e+02, 3.7600e+02],\n",
      "        [5.1723e+01, 3.0771e+02, 1.2346e+02, 3.7600e+02],\n",
      "        [2.8535e+02, 1.1490e+02, 3.8729e+02, 1.6977e+02],\n",
      "        [4.2668e+02, 9.5467e+01, 5.0783e+02, 3.2194e+02],\n",
      "        [2.4468e+02, 2.2693e+02, 3.4776e+02, 3.7600e+02],\n",
      "        [2.5046e+02, 2.4026e+02, 3.5561e+02, 2.9747e+02],\n",
      "        [2.9238e+02, 2.4515e+02, 3.8415e+02, 3.0022e+02],\n",
      "        [4.4573e+02, 2.4019e+02, 4.9079e+02, 2.8758e+02]],\n",
      "       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.5440, 0.5317, 0.5299, 0.5213, 0.5209, 0.5209, 0.5195, 0.5181, 0.5166,\n",
      "        0.5163, 0.5149, 0.5145, 0.5135, 0.5133, 0.5132, 0.5124, 0.5115, 0.5105,\n",
      "        0.5100, 0.5100, 0.5093, 0.5092, 0.5090, 0.5081, 0.5080, 0.5080, 0.5080,\n",
      "        0.5080, 0.5077, 0.5076, 0.5071, 0.5070, 0.5068, 0.5065, 0.5064, 0.5064,\n",
      "        0.5059, 0.5059, 0.5057, 0.5057, 0.5056, 0.5052, 0.5048, 0.5048, 0.5046,\n",
      "        0.5041, 0.5039, 0.5036, 0.5036, 0.5035, 0.5032, 0.5029, 0.5029, 0.5025,\n",
      "        0.5021, 0.5019, 0.5018, 0.5016, 0.5014, 0.5009, 0.5007, 0.5007, 0.5006,\n",
      "        0.5004, 0.5003, 0.4997, 0.4985, 0.4984, 0.4980, 0.4978, 0.4976, 0.4972,\n",
      "        0.4970, 0.4965, 0.4964, 0.4962, 0.4962, 0.4960, 0.4956, 0.4954, 0.4951,\n",
      "        0.4947, 0.4946, 0.4943, 0.4942, 0.4942, 0.4940, 0.4939, 0.4938, 0.4936,\n",
      "        0.4935, 0.4935, 0.4933, 0.4933, 0.4933, 0.4931, 0.4931, 0.4928, 0.4926,\n",
      "        0.4923], grad_fn=<IndexBackward0>)}]\n"
     ]
    }
   ],
   "source": [
    "first_input_image = first_image.clone()\n",
    "second_input_image = second_image.clone()\n",
    "\n",
    "inputs = [first_input_image.to(device), second_input_image.to(device)]\n",
    "\n",
    "ft_model.eval()\n",
    "output = ft_model(inputs)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9facc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(0.6533, grad_fn=<NllLossBackward0>),\n",
       " 'loss_box_reg': tensor(0.0425, grad_fn=<DivBackward0>),\n",
       " 'loss_objectness': tensor(0.6880, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " 'loss_rpn_box_reg': tensor(0.0066, grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_input_image = first_image.clone()\n",
    "first_target = {\n",
    "    'boxes': first_box.clone().to(device),\n",
    "    'labels' : first_label.clone().to(device)\n",
    "    \n",
    "} \n",
    "\n",
    "second_input_image = second_image.clone()\n",
    "second_target = {\n",
    "    'boxes': second_box.clone().to(device),\n",
    "    'labels' : second_label.clone().to(device)\n",
    "    \n",
    "} \n",
    "\n",
    "inputs = [first_input_image.to(device), second_input_image.to(device)]\n",
    "targets = [first_target, second_target]\n",
    "\n",
    "ft_model.train()\n",
    "ft_model(inputs, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
